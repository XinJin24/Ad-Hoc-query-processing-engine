import subprocess
import re


def read_arguments_from_file():
    # file_path = input("Enter the file path: ")
    file_path = r"C:\Users\jinxi\git_repos\Ad-Hoc-query-processing-engine\input1.txt"
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.readlines()

        keys = [
            'SELECT ATTRIBUTE(S):',
            'NUMBER OF GROUPING VARIABLES(n):',
            'GROUPING ATTRIBUTES(V):',
            'F-VECT([F]):',
            'SELECT CONDITION-VECT([σ]):',
            'HAVING_CONDITION(G):'
        ]
        parsed_data = {key: [] for key in keys}
        current_key = None

        for line in content:
            line = line.strip()
            if line in keys:
                current_key = line
            elif current_key and line:
                elements = [element.strip() for element in line.split(',')]
                parsed_data[current_key].extend(elements)

        if any(len(parsed_data[key]) == 0 for key in keys):
            raise ValueError("Some keys are missing data.")

        return parsed_data

    except FileNotFoundError:
        print("File not found. Please check the path and try again.")
        return None
    except ValueError as ve:
        print(ve)
        return None
    except UnicodeDecodeError:
        print("Encoding error: Please check the file encoding. It may not be UTF-8.")
        return None
    except Exception as e:
        print(f"An error occurred: {e}")
        return None


def get_arguments_manually():
    print("Please enter the 6 arguments for the Phi Operator:")
    return {
        'SELECT_ATTRIBUTE(S)': input("Enter SELECT ATTRIBUTE(S) (e.g., cust, 1_sum_quant, 2_sum_quant, 3_sum_quant): "),
        'NUMBER_OF_GROUPING_VARIABLES(n)': input("Enter NUMBER OF GROUPING VARIABLES(n) (e.g., 3): "),
        'GROUPING_ATTRIBUTES(V)': input("Enter GROUPING ATTRIBUTES(V) (e.g., cust): "),
        'F-VECT([F])': input(
            "Enter F-VECT([F]) (e.g., 1_sum_quant, 1_avg_quant, 2_sum_quant, 3_sum_quant, 3_avg_quant): "),
        'SELECT_CONDITION-VECT([σ])': input(
            "Enter SELECT CONDITION-VECT([σ]) (e.g., 1.state='NY', 2.state='NJ', 3.state='CT'): "),
        'HAVING_CONDITION(G)': input(
            "Enter HAVING_CONDITION(G) (e.g., 1_sum_quant > 2 * 2_sum_quant or 1_avg_quant > 3_avg_quant): ")
    }


def get_phi_operator_arguments():
    choice = input("Do you want to enter arguments manually or from a file? (Type 'manual' or 'file'): ").lower()
    if choice == 'file':
        return read_arguments_from_file()
    elif choice == 'manual':
        return get_arguments_manually()
    else:
        print("Invalid choice. Please enter 'manual' or 'file'.")
        return get_phi_operator_arguments()


def step1():
    arguments = get_phi_operator_arguments()
    if arguments is not None:
        print("Phi Operator Arguments:", arguments)
        return arguments


def step2(body):
    """
    This is the generator code. It should take in the MF structure and generate the code
    needed to run the query. That generated code should be saved to a
    file (e.g. _generated.py) and then run.
    """
    # Note: The f allows formatting with variables.
    #       Also, note the indentation is preserved.
    tmp = f"""
import os
import psycopg2
import psycopg2.extras
import tabulate
from prettytable import PrettyTable
from _H_class_generated import H
import collections
from dotenv import load_dotenv

# DO NOT EDIT THIS FILE, IT IS GENERATED BY generator.py

def query():
    load_dotenv()

    user = os.getenv('USER')
    password = os.getenv('PASSWORD')
    dbname = os.getenv('DBNAME')

    conn = psycopg2.connect("dbname="+dbname+" user="+user+" password="+password,
                            cursor_factory=psycopg2.extras.DictCursor)

    cur = conn.cursor()
    cur.execute("SELECT * FROM sales")
    rows = cur.fetchall()
    
    mf_structure = collections.defaultdict(H)
    {body}

    _global = []
    return tabulate.tabulate(_global,
                        headers="keys", tablefmt="psql")

def main():
    print(query())

if "__main__" == __name__:
    main()
    """

    # Write the generated code to a file
    with open("_generated.py", "w", encoding='utf-8') as file:
        file.write(tmp)
    # Execute the generated code
    subprocess.run(["python", "_generated.py"])


def generate_h_table(arguments):
    grouping_attributes = arguments['GROUPING ATTRIBUTES(V):']
    aggregate_functions = arguments['F-VECT([F]):']

    class_definition = "class H:\n"
    class_definition += "    def __init__(self):\n"
    class_definition += "        self.attributes = {}\n"

    for attr in grouping_attributes:
        formatted_attr = f"{attr}" if attr[0].isdigit() else attr
        class_definition += f"        self.attributes['{formatted_attr}'] = None\n"

    for func in aggregate_functions:
        formatted_func = f"{func}" if func[0].isdigit() else func
        if "min" in formatted_func:
            class_definition += f"        self.attributes['{formatted_func}'] = 10000\n"
        else:
            class_definition += f"        self.attributes['{formatted_func}'] = 0\n"

    class_definition += """
    def __getitem__(self, key):
        return self.attributes.get(key, None)

    def __setitem__(self, key, value):
        self.attributes[key] = value

    def __repr__(self):
        return f'H({self.attributes})'
        
    def __contains__(self, key):
        return key in self.attributes
    """

    filename = "_H_class_generated.py"
    with open(filename, 'w') as file:
        file.write(class_definition)

    print(f"Class H has been generated and saved to {filename}")
    return filename


def initializing_H_table(grouping_attributes, aggregate_functions):
    indentation = "    "
    generated_code = []

    formatted_group_keys = ", ".join([f"group_{attr}" for attr in grouping_attributes])
    group_dict_access = f"mf_structure[({formatted_group_keys})]"

    if 0 in aggregate_functions:
        aggregate_info = [(f[0], f[1], f[2]) for f in aggregate_functions[0]]
        for aggregate in aggregate_info:
            if "avg" in aggregate[1]:
                generated_code.append(f"{indentation}count_{aggregate[0]} = collections.defaultdict(int)")
                break

    generated_code.append("for row in rows:")

    schema_indices = {'cust': '0', 'prod': '1', 'day': '2', 'month': '3',
                      'year': '4', 'state': '5', 'quant': '6', "date": '7'}
    for attribute in grouping_attributes:
        generated_code.append(f"{indentation * 2}group_{attribute} = row[{schema_indices[attribute]}]")

    if 0 in aggregate_functions:
        aggregate_attr_set = set(info[2] for info in aggregate_info)
        for aggregate_attr in aggregate_attr_set:
            generated_code.append(f"{indentation * 2}{aggregate_attr} = row[{schema_indices[aggregate_attr]}]")

    return "\n".join(generated_code)


def templating_aggregates(aggregate_definitions):
    aggregate_mapping = {}
    for definition in aggregate_definitions:
        parts = definition.split("_")
        grouping_variable_index = int(parts[0])
        aggregate_function = parts[1]
        attribute_name = parts[2]

        if grouping_variable_index not in aggregate_mapping:
            aggregate_mapping[grouping_variable_index] = []
        aggregate_mapping[grouping_variable_index].append(
            (definition, grouping_variable_index, aggregate_function, attribute_name))

    return aggregate_mapping


def is_aggregate_condition(value, aggregate_mappings):
    aggregate_identifiers = set(func[0] for funcs in aggregate_mappings.values() for func in funcs)
    return value in aggregate_identifiers


def need_more_scan(predicates, aggregates):
    aggregate_names = set()
    for agg_list in aggregates.values():
        for agg in agg_list:
            aggregate_names.add(agg[0])
    for predicate in predicates:
        parts = re.split(r'([<>=]{1,2})', predicate)
        if len(parts) < 3:
            continue
        right_hand_side = parts[2].strip().replace('’', "'").replace('“', '"').strip("'\"")
        if right_hand_side in aggregate_names:
            return True
    return False


def scan_to_compute_aggregates(grouping_attributes, aggregate_mapping, predicate_conditions, schema_indices,
                               formatted_select_attributes):
    generated_code = []
    generated_code.append("")
    group_attr = "(" + ", ".join(["group_" +
                                  group_attr for group_attr in grouping_attributes]) + ")"

    for index, aggregates in aggregate_mapping.items():
        filtered_select_conditions = [cond for cond in predicate_conditions if cond.startswith(str(index))]
        code_for_aggregates = generate_aggregation_code(group_attr, aggregates, filtered_select_conditions,
                                                        schema_indices, aggregate_mapping,
                                                        formatted_select_attributes.get(index), index)
        generated_code.append(code_for_aggregates)

    return "\n".join(generated_code)


def generate_aggregation_code(group_attr, aggregates, predicate_conditions, schema_indices, all_aggregates,
                              select_attributes, index):
    generated_code = []
    indentation = "    "

    condition_list = []

    for condition in predicate_conditions:
        field_condition = condition.split('.')[1]
        if '>=' in field_condition:
            field, value = field_condition.split('>=')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] >= '{value.strip()[1:-1]}'")
            else:
                if not is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] >= {value}")
        elif '<=' in field_condition:
            field, value = field_condition.split('<=')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] <= '{value.strip()[1:-1]}'")
            else:
                if not is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] <= {value}")
        elif '!=' in field_condition:
            field, value = field_condition.split('!=')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] != '{value.strip()[1:-1]}'")
            else:
                if not is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] != {value}")
        elif '>' in field_condition:
            field, value = field_condition.split('>')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] > '{value.strip()[1:-1]}'")
            else:
                if not is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] > {value}")
        elif '<' in field_condition:
            field, value = field_condition.split('<')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] < '{value.strip()[1:-1]}'")
            else:
                if not is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] < {value}")
        elif '=' in field_condition:
            field, value = field_condition.split('=')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] == '{value.strip()[1:-1]}'")
            else:
                if not is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] == {value}")
    if condition_list:
        combined_conditions = ' and '.join(condition_list)
        generated_code.append(f"{indentation * 2}if {combined_conditions}:")

    formatted_group_keys = ", ".join([f"group_{attr}" for attr in grouping_attributes])
    group_dict_access = f"mf_structure[({formatted_group_keys})]"
    grouping_conditions = " and ".join([f"{group_dict_access}['{attr}']" for attr in grouping_attributes])
    generated_code.append(f"{indentation * 3}if not ({grouping_conditions}):")

    for attribute in grouping_attributes:
        generated_code.append(f"{indentation * 4}{group_dict_access}['{attribute}'] = group_{attribute}")
    for agg_name, grouping_variable_index, agg_type, agg_attr in aggregates:
        target_index = schema_indices[agg_attr]
        group_key = f"mf_structure[{group_attr}]['" + agg_name + "']"

        if agg_type == "sum":
            generated_code.append(f"{indentation * 3}{group_key} += row[{target_index}]")

            if select_attributes:
                for attr in select_attributes:
                    generated_code.extend([
                        f"{indentation * 3}mf_structure[{group_attr}]['{index}.{attr}'] = row[{schema_indices[attr]}]"
                    ])

        elif agg_type == "avg":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}_sum' not in mf_structure[{group_attr}]:",
                f"{indentation * 4}mf_structure[{group_attr}]['{agg_name}_sum'] = 0",
                f"{indentation * 4}mf_structure[{group_attr}]['{agg_name}_count'] = 0",
                f"{indentation * 3}mf_structure[{group_attr}]['{agg_name}_sum'] += row[{target_index}]",
                f"{indentation * 3}mf_structure[{group_attr}]['{agg_name}_count'] += 1"
            ])
            if select_attributes:
                for attr in select_attributes:
                    generated_code.extend([
                        f"{indentation * 3}mf_structure[{group_attr}]['{index}.{attr}'] = row[{schema_indices[attr]}]"
                    ])
        elif agg_type == "max":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}' not in mf_structure[{group_attr}] or row[{target_index}] > {group_key}:",
                f"{indentation * 4}{group_key} = row[{target_index}]"
            ])
            if select_attributes:
                for attr in select_attributes:
                    generated_code.extend([
                        f"{indentation * 3}mf_structure[{group_attr}]['{index}.{attr}'] = row[{schema_indices[attr]}]"
                    ])
        elif agg_type == "min":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}' not in mf_structure[{group_attr}] or row[{target_index}] < {group_key}:",
                f"{indentation * 4}{group_key} = row[{target_index}]"
            ])
            if select_attributes:
                for attr in select_attributes:
                    generated_code.extend([
                        f"{indentation * 3}mf_structure[{group_attr}]['{index}.{attr}'] = row[{schema_indices[attr]}]"
                    ])
        elif agg_type == "count":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}' not in mf_structure[{group_attr}]:",
                f"{indentation * 4}{group_key} = 1",
                f"{indentation * 3}else:",
                f"{indentation * 4}{group_key} += 1"
            ])
            if select_attributes:
                for attr in select_attributes:
                    generated_code.extend([
                        f"{indentation * 3}mf_structure[{group_attr}]['{index}.{attr}'] = row[{schema_indices[attr]}]"
                    ])

    return "\n".join(generated_code)


def generate_aggregation_code_for_second_scan(group_attr, aggregates, predicate_conditions, schema_indices,
                                              all_aggregates, index, select_attributes):
    generated_code = []
    indentation = "    "
    condition_list = []

    for condition in predicate_conditions:
        field_condition = condition.split('.')[1]
        if '>=' in field_condition:
            field, value = field_condition.split('>=')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] >= '{value.strip()[1:-1]}'")
            else:
                if is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] >= mf_structure[({group_attr})]['{value}']")
        elif '<=' in field_condition:
            field, value = field_condition.split('<=')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] <= '{value.strip()[1:-1]}'")
            else:
                if is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] <= mf_structure[({group_attr})]['{value}']")
        elif '!=' in field_condition:
            field, value = field_condition.split('!=')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] != '{value.strip()[1:-1]}'")
            else:
                if is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] != mf_structure[({group_attr})]['{value}']")
        elif '>' in field_condition:
            field, value = field_condition.split('>')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] > '{value.strip()[1:-1]}'")
            else:
                if is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] > mf_structure[({group_attr})]['{value}']")
        elif '<' in field_condition:
            field, value = field_condition.split('<')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] < '{value.strip()[1:-1]}'")
            else:
                if is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] < mf_structure[({group_attr})]['{value}']")
        elif '=' in field_condition:
            field, value = field_condition.split('=')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] == '{value.strip()[1:-1]}'")
            else:
                if is_aggregate_condition(value, all_aggregates):
                    condition_list.append(f"row[{field_index}] == mf_structure[({group_attr})]['{value}']")
    if condition_list:
        combined_conditions = ' and '.join(condition_list)
        generated_code.append(f"{indentation * 2}if {combined_conditions}:")

    formatted_group_keys = ", ".join([f"group_{attr}" for attr in grouping_attributes])
    group_dict_access = f"mf_structure_0[({formatted_group_keys})]"
    grouping_conditions = " and ".join([f"{group_dict_access}['{attr}']" for attr in grouping_attributes])
    generated_code.append(f"{indentation * 3}if not ({grouping_conditions}):")

    for attribute in grouping_attributes:
        generated_code.append(f"{indentation * 4}{group_dict_access}['{attribute}'] = group_{attribute}")
    for agg_name, grouping_variable_index, agg_type, agg_attr in aggregates:
        target_index = schema_indices[agg_attr]
        group_key = f"mf_structure_0[{group_attr}]['" + agg_name + "']"

        if agg_type == "sum":
            generated_code.append(f"{indentation * 3}{group_key} += row[{target_index}]")
            if select_attributes:
                for attr in select_attributes:
                    generated_code.extend([
                        f"{indentation * 3}mf_structure_0[{group_attr}]['{index}.{attr}'] = row[{schema_indices[attr]}]"
                    ])
        elif agg_type == "avg":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}_sum' not in mf_structure_0[{group_attr}]:",
                f"{indentation * 4}mf_structure_0[{group_attr}]['{agg_name}_sum'] = 0",
                f"{indentation * 4}mf_structure_0[{group_attr}]['{agg_name}_count'] = 0",
                f"{indentation * 3}mf_structure_0[{group_attr}]['{agg_name}_sum'] += row[{target_index}]",
                f"{indentation * 3}mf_structure_0[{group_attr}]['{agg_name}_count'] += 1"
            ])
            if select_attributes:
                for attr in select_attributes:
                    generated_code.extend([
                        f"{indentation * 3}mf_structure_0[{group_attr}]['{index}.{attr}'] = row[{schema_indices[attr]}]"
                    ])
        elif agg_type == "max":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}' not in mf_structure_0[{group_attr}] or row[{target_index}] > {group_key}:",
                f"{indentation * 4}{group_key} = row[{target_index}]"
            ])
            if select_attributes:
                for attr in select_attributes:
                    generated_code.extend([
                        f"{indentation * 3}mf_structure_0[{group_attr}]['{index}.{attr}'] = row[{schema_indices[attr]}]"
                    ])
        elif agg_type == "min":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}' not in mf_structure_0[{group_attr}] or row[{target_index}] < {group_key}:",
                f"{indentation * 4}{group_key} = row[{target_index}]"
            ])
            if select_attributes:
                for attr in select_attributes:
                    generated_code.extend([
                        f"{indentation * 3}mf_structure_0[{group_attr}]['{index}.{attr}'] = row[{schema_indices[attr]}]"
                    ])
        elif agg_type == "count":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}' not in mf_structure_0[{group_attr}]:",
                f"{indentation * 4}{group_key} = 1",
                f"{indentation * 3}else:",
                f"{indentation * 4}{group_key} += 1"
            ])
            if select_attributes:
                for attr in select_attributes:
                    generated_code.extend([
                        f"{indentation * 3}mf_structure_0[{group_attr}]['{index}.{attr}'] = row[{schema_indices[attr]}]"
                    ])

    return "\n".join(generated_code)


def extract_variable_that_needs_second_scan(select_conditions, aggregates):
    variable_indices = set()
    aggregate_names = set(agg[0] for aggs in aggregates.values() for agg in aggs)
    operator_regex = r'[<>=!]{1,2}'
    for condition in select_conditions:
        parts = re.split(operator_regex, condition)
        if len(parts) > 1:
            left_hand_side = parts[0].strip()
            right_hand_side = parts[1].strip()
            if any(agg in right_hand_side for agg in aggregate_names):
                match = re.match(r'(\d+)\.', left_hand_side)
                if match:
                    variable_index = int(match.group(1))
                    variable_indices.add(variable_index)
    return variable_indices


def second_scan(grouping_attributes, aggregate_functions, select_conditions, all_aggregate_functions, index,
                formatted_select_attributes):
    generated_code = []
    indentation = "    "
    group_attr = "(" + ", ".join(["group_" +
                                  group_attr for group_attr in grouping_attributes]) + ")"
    generated_code.append(indentation + "for row in rows:")

    schema_indices = {'cust': '0', 'prod': '1', 'day': '2', 'month': '3',
                      'year': '4', 'state': '5', 'quant': '6', "date": '7'}

    for attribute in grouping_attributes:
        generated_code.append(f"{indentation * 2}group_{attribute} = row[{schema_indices[attribute]}]")

    filtered_select_conditions = [cond for cond in select_conditions if cond.startswith(str(index))]
    generated_code.append(generate_aggregation_code_for_second_scan(group_attr, aggregate_functions,
                                                                    filtered_select_conditions, schema_indices,
                                                                    all_aggregate_functions, index,
                                                                    formatted_select_attributes.get(index)))

    return "\n".join(generated_code)


def get_average_script(h_table_name):
    return f"""
                \n
    for key_tuple, h_object in {h_table_name}.items():
        attributes = h_object.attributes
        keys_to_remove = []
        for attr_key in list(attributes.keys()):
            if attr_key.endswith('_sum') and attr_key[:-4] + '_count' in attributes:
                base_key = attr_key[:-4]
                sum_value = attributes[attr_key]
                count_key = base_key + '_count'
                count_value = attributes[count_key]
                if count_value != 0:
                    attributes[base_key] = round(sum_value / count_value, 2)
                else:
                    attributes[base_key] = 0
                keys_to_remove.extend([attr_key, count_key])
        for key in keys_to_remove:
            del attributes[key]
    """


def override_tables():
    return f"""
    \n
    for key, updated_h_object in mf_structure_0.items():
        if key in mf_structure:
            original_h_object = mf_structure[key]
            for attr, value in updated_h_object.attributes.items():
                if value != 0:
                    original_h_object.attributes[attr] = value
        else:
            mf_structure[key] = updated_h_object
        """


def update_mf_structure(original_structure, updates):
    for key, updated_h_object in updates.items():
        if key in original_structure:
            original_h_object = original_structure[key]
            for attr, value in updated_h_object.attributes.items():
                original_h_object.attributes[attr] = value
        else:
            original_structure[key] = updated_h_object


def parse_select_attributes(attributes):
    parsed_attrs = {}
    for attribute in attributes:
        if "." in attribute:
            level, attr_name = attribute.split(".")
            level = int(level)
            if level not in parsed_attrs:
                parsed_attrs[level] = []
            parsed_attrs[level].append(attr_name)
    return parsed_attrs


def parse_having(having_clause):
    processed_conditions = []
    condition_parts = re.split('(and|or)', having_clause)
    comparison_operators = ["==", "<=", ">=", "<", ">", "!="]

    for condition in condition_parts:
        if condition in ['and', 'or']:
            processed_conditions.append(condition)
            continue
        operator = next((op for op in comparison_operators if op in condition), "!=")
        split_condition = re.split('({})'.format(operator), condition)
        left_side, right_side = split_condition[0].strip(), split_condition[2].strip()
        left_side_formatted = ' '.join(
            ['val["' + element + '"]' if "." in element or "_" in element else element for element in
             left_side.split()])
        right_side_formatted = ' '.join(
            ['val["' + element + '"]' if "." in element or "_" in element else element for element in
             right_side.split()])
        full_condition = f"{left_side_formatted} {operator} {right_side_formatted}"
        processed_conditions.append(full_condition)

    return ' '.join(processed_conditions)


def generateOutput(S, G):
    script = "\n"
    indentation = "    "
    my_string = ','.join(f"'{item}'" for item in S)
    output = ""
    output += (indentation + "x = PrettyTable()\n")
    output += (indentation + f"x.field_names = [" + my_string + "]\n")
    output += (indentation + "for val in mf_structure.values():\n")
    if len(G) and len(G[0]):
        having = parse_having(G[0])
        output += (indentation * 2 + "if " + having + ":\n")

    output += (indentation * 3 + "row = [val[key] for key in x.field_names if key in val]\n")
    output += (indentation * 3 + "x.add_row(row)\n")

    output += (indentation + "print(x)\n")
    script += output
    return script


if "__main__" == __name__:
    body = ""
    indentation = "    "
    schema_indices = {'cust': 0, 'prod': 1, 'day': 2, 'month': 3, 'year': 4, 'state': 5, 'quant': 6, 'date': 7}
    phi_arguments = step1()
    grouping_attributes = phi_arguments['GROUPING ATTRIBUTES(V):']
    aggregate_functions = phi_arguments['F-VECT([F]):']
    select_conditions = phi_arguments['SELECT CONDITION-VECT([σ]):']
    n_of_grouping = phi_arguments["NUMBER OF GROUPING VARIABLES(n):"]
    select_attributes = phi_arguments["SELECT ATTRIBUTE(S):"]
    having_condition = phi_arguments["HAVING_CONDITION(G):"]
    formatted_select_attributes = parse_select_attributes(select_attributes)

    aggregate_functions = templating_aggregates(aggregate_functions)
    file_name = generate_h_table(phi_arguments)
    body += initializing_H_table(grouping_attributes, aggregate_functions)

    body += scan_to_compute_aggregates(grouping_attributes, aggregate_functions, select_conditions, schema_indices,
                                       formatted_select_attributes)

    avg_added = False

    for key, values in aggregate_functions.items():
        if avg_added:
            break
        for value in values:
            if '_avg_' in value[0]:
                body += get_average_script("mf_structure")
        avg_added = True
        break

    if need_more_scan(select_conditions, aggregate_functions):
        generated_code = []
        body += "\n"
        body += "\n".join(["    # second scan"])
        body += "\n"
        body += "\n".join(["    mf_structure_0 = collections.defaultdict(H)"])
        re_scan_vars = extract_variable_that_needs_second_scan(select_conditions, aggregate_functions)
        filtered_aggregates = {key: aggregates for key, aggregates in aggregate_functions.items() if
                               key in re_scan_vars}
        for i in range(1, int(len(re_scan_vars) + 1)):
            body += "\n"
            body += second_scan(grouping_attributes, aggregate_functions.get(i), select_conditions, aggregate_functions,
                                i, formatted_select_attributes)
        avg_added = False
        for key, values in aggregate_functions.items():
            if avg_added:
                break
            for value in values:
                if '_avg_' in value[0]:
                    body += get_average_script("mf_structure_0")
            avg_added = True
            break
        body += override_tables()
    body += generateOutput(select_attributes, having_condition)
    step2(body)
