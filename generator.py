import subprocess


def read_arguments_from_file():
    # file_path = input("Enter the file path: ")
    file_path = r"C:\Users\jinxi\git_repos\Ad-Hoc-query-processing-engine\input1.txt"
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.readlines()

        keys = [
            'SELECT ATTRIBUTE(S):',
            'NUMBER OF GROUPING VARIABLES(n):',
            'GROUPING ATTRIBUTES(V):',
            'F-VECT([F]):',
            'SELECT CONDITION-VECT([σ]):',
            'HAVING_CONDITION(G):'
        ]
        parsed_data = {key: [] for key in keys}
        current_key = None

        for line in content:
            line = line.strip()
            if line in keys:
                current_key = line
            elif current_key and line:
                elements = [element.strip() for element in line.split(',')]
                parsed_data[current_key].extend(elements)

        if any(len(parsed_data[key]) == 0 for key in keys):
            raise ValueError("Some keys are missing data.")

        return parsed_data

    except FileNotFoundError:
        print("File not found. Please check the path and try again.")
        return None
    except ValueError as ve:
        print(ve)
        return None
    except UnicodeDecodeError:
        print("Encoding error: Please check the file encoding. It may not be UTF-8.")
        return None
    except Exception as e:
        print(f"An error occurred: {e}")
        return None


def get_arguments_manually():
    print("Please enter the 6 arguments for the Phi Operator:")
    return {
        'SELECT_ATTRIBUTE(S)': input("Enter SELECT ATTRIBUTE(S) (e.g., cust, 1_sum_quant, 2_sum_quant, 3_sum_quant): "),
        'NUMBER_OF_GROUPING_VARIABLES(n)': input("Enter NUMBER OF GROUPING VARIABLES(n) (e.g., 3): "),
        'GROUPING_ATTRIBUTES(V)': input("Enter GROUPING ATTRIBUTES(V) (e.g., cust): "),
        'F-VECT([F])': input(
            "Enter F-VECT([F]) (e.g., 1_sum_quant, 1_avg_quant, 2_sum_quant, 3_sum_quant, 3_avg_quant): "),
        'SELECT_CONDITION-VECT([σ])': input(
            "Enter SELECT CONDITION-VECT([σ]) (e.g., 1.state='NY', 2.state='NJ', 3.state='CT'): "),
        'HAVING_CONDITION(G)': input(
            "Enter HAVING_CONDITION(G) (e.g., 1_sum_quant > 2 * 2_sum_quant or 1_avg_quant > 3_avg_quant): ")
    }


def get_phi_operator_arguments():
    choice = input("Do you want to enter arguments manually or from a file? (Type 'manual' or 'file'): ").lower()
    if choice == 'file':
        return read_arguments_from_file()
    elif choice == 'manual':
        return get_arguments_manually()
    else:
        print("Invalid choice. Please enter 'manual' or 'file'.")
        return get_phi_operator_arguments()


def step1():
    arguments = get_phi_operator_arguments()
    if arguments is not None:
        print("Phi Operator Arguments:", arguments)
        return arguments


def step2(body):
    """
    This is the generator code. It should take in the MF structure and generate the code
    needed to run the query. That generated code should be saved to a
    file (e.g. _generated.py) and then run.
    """
    # Note: The f allows formatting with variables.
    #       Also, note the indentation is preserved.
    tmp = f"""
import os
import psycopg2
import psycopg2.extras
import tabulate
from _H_class_generated import H
import collections
from dotenv import load_dotenv

# DO NOT EDIT THIS FILE, IT IS GENERATED BY generator.py

def query():
    load_dotenv()

    user = os.getenv('USER')
    password = os.getenv('PASSWORD')
    dbname = os.getenv('DBNAME')

    conn = psycopg2.connect("dbname="+dbname+" user="+user+" password="+password,
                            cursor_factory=psycopg2.extras.DictCursor)

    cur = conn.cursor()
    cur.execute("SELECT * FROM sales")
    rows = cur.fetchall()
    
    mf_structure = collections.defaultdict(H)
    {body}

    _global = []
    return tabulate.tabulate(_global,
                        headers="keys", tablefmt="psql")

def main():
    print(query())

if "__main__" == __name__:
    main()
    """

    # Write the generated code to a file
    with open("_generated.py", "w", encoding='utf-8') as file:
        file.write(tmp)
    # Execute the generated code
    subprocess.run(["python", "_generated.py"])


def generate_h_table(arguments):
    grouping_attributes = arguments['GROUPING ATTRIBUTES(V):']
    aggregate_functions = arguments['F-VECT([F]):']

    class_definition = "class H:\n"
    class_definition += "    def __init__(self):\n"
    class_definition += "        self.attributes = {}\n"

    for attr in grouping_attributes:
        formatted_attr = f"{attr}" if attr[0].isdigit() else attr
        class_definition += f"        self.attributes['{formatted_attr}'] = None\n"

    for func in aggregate_functions:
        formatted_func = f"{func}" if func[0].isdigit() else func
        class_definition += f"        self.attributes['{formatted_func}'] = 0\n"

    class_definition += """
    def __getitem__(self, key):
        return self.attributes.get(key, None)

    def __setitem__(self, key, value):
        self.attributes[key] = value

    def __repr__(self):
        return f'H({self.attributes})'
        
    def __contains__(self, key):
        return key in self.attributes
    """

    filename = "_H_class_generated.py"
    with open(filename, 'w') as file:
        file.write(class_definition)

    print(f"Class H has been generated and saved to {filename}")
    return filename


def initializing_H_table(grouping_attributes, aggregate_functions):
    indentation = "    "
    generated_code = []

    formatted_group_keys = ", ".join([f"group_{attr}" for attr in grouping_attributes])
    group_dict_access = f"mf_structure[({formatted_group_keys})]"

    if 0 in aggregate_functions:
        aggregate_info = [(f[0], f[1], f[2]) for f in aggregate_functions[0]]
        print(aggregate_info)
        for aggregate in aggregate_info:
            if "avg" in aggregate[1]:
                generated_code.append(f"{indentation}count_{aggregate[0]} = collections.defaultdict(int)")
                break

    generated_code.append("for row in rows:")

    schema_indices = {'cust': '0', 'prod': '1', 'day': '2', 'month': '3',
                      'year': '4', 'state': '5', 'quant': '6', "date": '7'}
    for attribute in grouping_attributes:
        generated_code.append(f"{indentation * 2}group_{attribute} = row[{schema_indices[attribute]}]")

    if 0 in aggregate_functions:
        aggregate_attr_set = set(info[2] for info in aggregate_info)
        for aggregate_attr in aggregate_attr_set:
            generated_code.append(f"{indentation * 2}{aggregate_attr} = row[{schema_indices[aggregate_attr]}]")

    return "\n".join(generated_code)


def templating_aggregates(aggregate_definitions):
    aggregate_mapping = {}
    for definition in aggregate_definitions:
        parts = definition.split("_")
        grouping_variable_index = int(parts[0])
        aggregate_function = parts[1]
        attribute_name = parts[2]

        if grouping_variable_index not in aggregate_mapping:
            aggregate_mapping[grouping_variable_index] = []
        aggregate_mapping[grouping_variable_index].append(
            (definition, grouping_variable_index, aggregate_function, attribute_name))

    return aggregate_mapping


def scan_to_compute_aggregates(grouping_attributes, aggregate_mapping,  select_conditions, schema_indices):
    generated_code = []
    generated_code.append("")
    group_attr = "(" + ", ".join(["group_" +
                                  group_attr for group_attr in grouping_attributes]) + ")"
    for index, aggregates in aggregate_mapping.items():
        filtered_select_conditions = [cond for cond in select_conditions if cond.startswith(str(index))]
        code_for_aggregates = generate_aggregation_code(group_attr, aggregates, filtered_select_conditions, schema_indices)
        generated_code.append(code_for_aggregates)

    return "\n".join(generated_code)


def generate_aggregation_code(group_attr, aggregates, select_conditions, schema_indices):
    generated_code = []
    indentation = "    "

    condition_list = []
    for condition in select_conditions:
        field_condition = condition.split('.')[1]
        if '>=' in field_condition:
            field, value = field_condition.split('>=')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] >= '{value.strip()[1:-1]}'")
            else:
                condition_list.append(f"row[{field_index}] >= {value}")
        if '<=' in field_condition:
            field, value = field_condition.split('<=')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] <= '{value.strip()[1:-1]}'")
            else:
                condition_list.append(f"row[{field_index}] <= {value}")
        if '>' in field_condition:
            field, value = field_condition.split('>')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] > '{value.strip()[1:-1]}'")
            else:
                condition_list.append(f"row[{field_index}] > {value}")
        if '<' in field_condition:
            field, value = field_condition.split('<')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] < '{value.strip()[1:-1]}'")
            else:
                condition_list.append(f"row[{field_index}] < {value}")
        if '=' in field_condition:
            field, value = field_condition.split('=')
            field_index = schema_indices[field]
            if "'" in value or '’' in value:
                condition_list.append(f"row[{field_index}] == '{value.strip()[1:-1]}'")
            else:
                condition_list.append(f"row[{field_index}] == {value}")
    if condition_list:
        combined_conditions = ' and '.join(condition_list)
        generated_code.append(f"{indentation * 2}if {combined_conditions}:")

    formatted_group_keys = ", ".join([f"group_{attr}" for attr in grouping_attributes])
    group_dict_access = f"mf_structure[({formatted_group_keys})]"
    grouping_conditions = " and ".join([f"{group_dict_access}['{attr}']" for attr in grouping_attributes])
    generated_code.append(f"{indentation * 3}if not ({grouping_conditions}):")

    for attribute in grouping_attributes:
        generated_code.append(f"{indentation * 4}{group_dict_access}['{attribute}'] = group_{attribute}")
    for agg_name, grouping_variable_index, agg_type, agg_attr in aggregates:
        target_index = schema_indices[agg_attr]
        group_key = f"mf_structure[{group_attr}]['" + agg_name + "']"

        if agg_type == "sum":
            generated_code.append(f"{indentation * 3}{group_key} += row[{target_index}]")
        elif agg_type == "avg":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}_sum' not in mf_structure[{group_attr}]:",
                f"{indentation * 4}mf_structure[{group_attr}]['{agg_name}_sum'] = 0",
                f"{indentation * 4}mf_structure[{group_attr}]['{agg_name}_count'] = 0",
                f"{indentation * 3}mf_structure[{group_attr}]['{agg_name}_sum'] += row[{target_index}]",
                f"{indentation * 3}mf_structure[{group_attr}]['{agg_name}_count']  += 1"
            ])
        elif agg_type == "max":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}' not in mf_structure[{group_attr}] or row[{target_index}] > {group_key}:",
                f"{indentation * 4}{group_key} = row[{target_index}]"
            ])
        elif agg_type == "min":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}' not in mf_structure[{group_attr}] or row[{target_index}] < {group_key}:",
                f"{indentation * 4}{group_key} = row[{target_index}]"
            ])
        elif agg_type == "count":
            generated_code.extend([
                f"{indentation * 3}if '{agg_name}' not in mf_structure[{group_attr}]:",
                f"{indentation * 4}{group_key} = 1",
                f"{indentation * 3}else:",
                f"{indentation * 4}{group_key} += 1"
            ])

    return "\n".join(generated_code)


if "__main__" == __name__:
    body = ""
    schema_indices = {'cust': 0, 'prod': 1, 'day': 2, 'month': 3, 'year': 4, 'state': 5, 'quant': 6, 'date': 7}
    phi_arguments = step1()
    grouping_attributes = phi_arguments['GROUPING ATTRIBUTES(V):']
    aggregate_functions = phi_arguments['F-VECT([F]):']
    select_conditions = phi_arguments['SELECT CONDITION-VECT([σ]):']

    aggregate_functions = templating_aggregates(aggregate_functions)
    file_name = generate_h_table(phi_arguments)
    print(aggregate_functions)
    body += initializing_H_table(grouping_attributes, aggregate_functions)
    body += scan_to_compute_aggregates(grouping_attributes, aggregate_functions, select_conditions, schema_indices)

    generated_code = []
    body += "\n"
    body += "\n".join(["    print(mf_structure)"])

    step2(body)
